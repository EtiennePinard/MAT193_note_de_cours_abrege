\section{Valeurs et vecteurs propres d'une matrice carré}

\subsection{Valeurs et vecteurs propres}
Soit $A \in M_{n \times n}(F)$
\begin{definition}
    $\lambda \in F$ valeur propre de $A \iff \exists \ u \in M_{n \times 1}(F), u \neq 0$ t.q. $Au = \lambda u$ \\
    Dans ce cas $u$ est dit le vecteur propre de $A$ associé à $\lambda$
\end{definition}
\begin{remark}
    Un vecteur propre est jamais nulle, mais une valeur propre peux être nulle
\end{remark}
\begin{definition}
    Le polynôme caractéristique de $A$ est $\chi_A(\lambda) = \det(A - \lambda I)$
\end{definition}
\begin{theorem}
    Les valeurs propres de $A$ sont les racines du polynôme caractéristique de $A$, c-à-d
    \[
        \lambda_0 \ \text{valeur propre de} \ A \iff \chi_A(\lambda_0) = 0
    \]
\end{theorem}
\subsubsection{Comment calculer les vecteurs propres}
\begin{enumerate}
    \item Trouver les racines de $\chi_A(\lambda)$
    \item Trouver toutes les solutions linéairement indépendantes du système homogène $(A - \lambda_0 I)X = \mathbb{O}$
          pour tout $\lambda_0$ valeurs propres de $A$.
    \item[] Note: Il se peut qu'une valeur propre ait plusieurs vecteurs propres linéairement indépendants.
\end{enumerate}
\subsubsection{Multiplicités et espace propre}
Grâce au théorème fondamentale de l'algèbre [\ref{theorem_fondamental_algebra}] on peut
exprimer le polynôme caractéristique à l'aide de ces racines, qui sont les valeurs propres
de $A$. Posons que $A$ a $m$ uniques valeurs propres. Alors
$\chi_A(\lambda) = (-1)^n(\lambda - \lambda_1)^{k_1}(\lambda - \lambda_2)^{k_2} \dots (\lambda - \lambda_m)^{k_m}
    \quad k_1 + k_2 + \dots + k_m = n, \ k_j \in \N$
\begin{definition}
    La multiplicité algébrique de la valeur propre $\lambda_j$ est le $k_j$ associé à $\lambda_j$
\end{definition}
\begin{definition}
    L'espace propre associé à $\lambda_j$ est
    $L_{\lambda_j} = \left\{ v \in M_{n \times 1} \mid Av = \lambda_j v \right\} \cup \left\{\mathbb{O} \in M_{n \times 1}\right\}$
\end{definition}
\begin{definition}
    La dimension de l'espace propre $L_{\lambda_j}$ est la multiplicité géométrique de $\lambda_j$
\end{definition}
\begin{lemma}
    $1 \leq \text{multiplicité géométrique de} \ \lambda_j \leq \text{multiplicité algébrique de} \ \lambda_j \leq n$
\end{lemma}

\subsection{Propriétés des valeurs propres}
Soit $A \in M_{n \times n}(\C)$
\paragraph{Propriété 1:} Si $B = \{v_1, \dots, v_n\}$ est un ensemble de vecteurs propres de $A$
associés à des valeurs propres distincts alors $B$ est linéairement indépendant.
\paragraph{Propriété 2:} Si $\lambda_0$ est une valeur propre de $A$ alors $(\lambda_0)^k$ est une
valeur propre de $A^k$, $k \in \N$
\paragraph{Propriété 3:} Si $\lambda_0$ est une valeur propre de $A$ et $A$ est inversible alors
$\frac{1}{\lambda_0}$ est une valeur propre de $A^{-1}$
\paragraph{Propriété 4:} Si $\det A = 0$ alors $\lambda_0 = 0$ est une valeur propre de $A$
\paragraph{Propriété 5:} $\det A = \lambda_1 \dots \lambda_n$ ou $\lambda_j$ est une valeur propre de $A$
\paragraph{Propriété 6:} $\text{tr} A = \lambda_1 + \dots + \lambda_n$ ou $\lambda_j$ est une valeur propre de $A$
\paragraph{Propriété 7:} $A$ et $A^T$ ont les même valeurs propres.
\paragraph{Propriété 8:} Si $A$ est triangulaire alors les valeurs propres de $A$ sont sa diagonale.
\paragraph{Propriété 9:} Les valeurs propres d'une matrice hermitienne sont réels
\paragraph{Propriété 10:} Si $A$ est hermitienne et que $v_1, v_2$ sont deux vecteurs propres de
$A$ associés à deux valeurs propres de $A$ distincts, soit $\lambda_1$ et $\lambda_2$, alors $v_1 \perp v_2$
et $L_{\lambda_1} \perp L_{\lambda_2}$ par rapport au produit scalaire canonique dans $\C^n$
\paragraph{Propriété 11:} \label{property_11} Si $A$ hermitienne, alors les vecteurs propres de $A$ forment une base orthonormale de $\C^n$

\subsection{Diagonalisation d'une matrice}
\begin{definition}
    Soit $A, P \in M_{n \times n}$ t.q. $P$ inversible, alors $A$ et $P^{-1}AP$ (ou $PAP^{-1}$) sont appellé semblabes
\end{definition}
\begin{remark}
    $\det(P^{-1}AP) = \det(PAP^{-1}) = \det A$ \\
    De plus, les valeurs propres de $A$ et $P^{-1}AP$ coïncident.
\end{remark}
\begin{definition}
    $A \in M_{n \times n}$ est diagonalisable $\iff \exists \ P \in M_{n \times n}$ inversible t.q. $P^{-1}AP$ diagonale
\end{definition}
\begin{theorem}
    $A \in M_{n \times n}$ est diagonalisable $\iff A$ admet $n$ vecteurs propres linéairement indépendant \\
    Dans ce cas on a que \[P = \begin{bmatrix}
            v_1 & v_2 & \dots & v_n
        \end{bmatrix} \ \text{avec} \ v_1, v_2, \dots, v_n \ \text{les vecteurs propres de} \ A\] 
        De plus, on a que
        \[P^{-1}AP = \text{diag}\{\lambda_1, \dots, \lambda_n\} \ \text{avec} \ \lambda_1, \dots, \lambda_n 
        \ \text{les valeurs propres de} \ A\] 
\end{theorem}
\begin{corollary}
    Si $A$ a $n$ valeurs propres distincts, alors $A$ est diagonalisable
\end{corollary}
\begin{corollary}
    Une matrice hermitienne est toujours diagonalisable à cause de \ref{property_11}
\end{corollary}
\begin{corollary}
    \label{hermitienne_implies_unitaire_P}
    Si $A$ hermitienne alors $\exists \ P$ unitaire t.q. $P^{-1}AP = P^\dagger A P$ diagonale
\end{corollary}
\begin{remark}
    La preuve de \ref{hermitienne_implies_unitaire_P} utilise cette équivalence, soit
    \[
        \begin{matrix}
            P \ \text{unitaire} \iff & \text{les colonnes de} \ P \ \text{forment une base orthonormale dans} \\
                                     & \C^n \ \text{par rapport au produit scalaire canonique}
        \end{matrix}
    \]
\end{remark}

\subsection{Fonctions d'une matrice}
Soit $f(x) \in \C_n[x]$, ou $\C_n[x]$ est l'espace des polynômes complexes à exposant au plus $n$
\begin{definition}
    Soit $A \in M_{n \times n}(\C)$, alors $f(A) = \alpha_0 I + \alpha_1 A + \dots + \alpha_n A^n$
\end{definition}
Un autre cas considéré dans ce cours est $f(z) = e^z = \sum_{k = 0}^{\infty}\frac{z^k}{k!}$
\begin{definition}
    Soit $A \in M_{n \times n}(\C)$, alors $e^A = \sum_{k = 0}^{\infty}\frac{A^k}{k!} = I + A + \frac{A^2}{2!} + \frac{A^3}{3!} + \dots$
\end{definition}

\subsubsection{Comment calculer \texorpdfstring{$f(A)$}{f(A)}}
Il a quatre choses qui peut nous aider pour calculer $f(A)$
\begin{enumerate}
    \item $A$ est nilpotente d'incide $k$, c-à-d que $A^k = \mathbb{O}$, donc on doit seulement 
    calculer les $k + 1$ premiers termes de $f(A)$
    \item Il existe une formule pour les puissances de $A$ (souvent prouver par récurrence),
    alors il est possible d'utiliser cette formule pour simplifier le calcul
    \item $A = \text{diag}\{\lambda_1, \dots, \lambda_n \} \implies f(A) = \text{diag}\{f(\lambda_1), \dots, f(\lambda_n)\}$
    \item Si $A$ est diagonalisable alors $A = PDP^{-1}$ avec $D = \text{diag}\{\lambda_1, \dots, \lambda_n\}$ \\
    Alors $f(A) = Pf(D)P^{-1} = P\text{diag}\{f(\lambda_1), \dots, f(\lambda_n)\}P^{-1}$
\end{enumerate}
\begin{remark}
    Si $A$ est non diagonalisable et qu'il n'existe pas de formule pour les puissances de $A$,
    il faut calculer tout les termes de $f(A)$ pour obtenir la réponse. 
\end{remark}

\subsubsection{Propriétés de l'exponentielle d'une matrice}
\begin{enumerate}
    \item Comme $A$ commute avec $A^k \ \forall \ k \in \N$ alors $A$ commute avec $e^A$
    \item Si $AB = BA$, soit que $A$ et $B$ commute alors $e^{A + B} = e^A e^B$
    \item $e^A$ inversible $\forall \ A \in M_{n \times n}$ avec $\left(e^A\right)^{-1} = e^{-A}$ 
    \item Si $A$ est hermitienne alors $e^{iA}$ est unitaire
\end{enumerate}